# 如何添加新网络架构

本文档说明如何将现有的VGG16近似探索逻辑应用到其他网络架构（如AlexNet、VGG11、VGG13、VGG19等）。

## 目录
1. [核心概念](#核心概念)
2. [添加新网络的步骤](#添加新网络的步骤)
3. [AlexNet示例](#alexnet示例)
4. [其他网络示例](#其他网络示例)
5. [常见问题](#常见问题)

---

## 核心概念

### 1. 关键组件

本项目的核心机制包括：

- **QuantStub/DeQuantStub**: PyTorch量化的入口和出口
- **ActivationRecorder**: 记录和编辑激活值的工具类
- **fuse_model()**: 融合Conv+BN+ReLU以提高量化效率
- **Tap点命名规范**: 统一的激活值记录点命名方式

### 2. Tap点命名规范

为了让近似探索系统正确工作，需要遵循以下命名规范：

**融合前**（训练阶段）：
- `block_input.{layer_name}`: 层的输入
- `features.{layer_name}.conv_out`: 卷积输出
- `features.{layer_name}.bn_out`: BN输出
- `features.{layer_name}.relu_out`: ReLU输出

**融合后**（推理阶段）：
- `block_output.{layer_name}`: 融合后的块输出

**分类器**：
- `block_input.classifier.{fc_name}`: 全连接层输入
- `classifier.{fc_name}.linear_out`: 线性层输出
- `classifier.{fc_name}.bn_out`: BN输出（如果有）
- `classifier.{fc_name}.relu_out`: ReLU输出
- `classifier.{fc_name}.out`: 融合后的全连接块输出

---

## 添加新网络的步骤

### 步骤1: 创建模型文件

创建 `model_{网络名}_tap_quant.py` 文件，例如 `model_alexnet_tap_quant.py`。

### 步骤2: 实现必要的组件

#### 2.1 导入依赖
```python
from collections import OrderedDict
from typing import Optional

import torch
import torch.nn as nn
from torch.ao.quantization import QuantStub, DeQuantStub, fuse_modules

from recorder import ActivationRecorder
```

#### 2.2 定义基础构建块
```python
def conv_seq(in_ch, out_ch, k=3, s=1, p=1):
    """卷积序列：conv + bn + relu"""
    return nn.Sequential(OrderedDict([
        ("conv", nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)),
        ("bn",   nn.BatchNorm2d(out_ch)),
        ("relu", nn.ReLU(inplace=True)),
    ]))
```

#### 2.3 实现模型类

模型类必须包含以下关键方法：

```python
class YourNetTapQuant(nn.Module):
    def __init__(self, num_classes: int = 10):
        super().__init__()
        self.quant = QuantStub()
        self.dequant = DeQuantStub()
        # ... 定义层 ...
    
    def fuse_model(self):
        """融合conv+bn+relu"""
        # 实现融合逻辑
        pass
    
    def _forward_convseq(self, x, seq, name, rec):
        """处理卷积序列，支持记录和编辑"""
        # 实现记录逻辑
        pass
    
    def forward(self, x, recorder=None):
        """前向传播"""
        x = self.quant(x)
        # ... 网络逻辑 ...
        x = self.dequant(x)
        return x
```

#### 2.4 实现辅助函数

```python
def get_yournet_layer_names():
    """返回所有需要近似探索的层名称"""
    return ["conv1", "conv2", ...]

def get_yournet_tap_points():
    """返回所有tap点的映射"""
    return {
        "conv1": "block_output.conv1",
        # ...
    }
```

### 步骤3: 更新配置文件

在 `model_configs.py` 中添加新模型的配置：

```python
class YourNetConfig(ModelConfig):
    def __init__(self, num_classes: int = 10):
        from model_yournet_tap_quant import YourNetTapQuant
        super().__init__("YourNet", YourNetTapQuant, num_classes)
    
    def get_layer_names(self) -> List[str]:
        # 返回层名称列表
        pass
    
    def get_tap_points(self) -> Dict[str, str]:
        # 返回tap点映射
        pass
```

然后在注册表中注册：
```python
MODEL_REGISTRY: Dict[str, Type[ModelConfig]] = {
    # ... 现有模型 ...
    "yournet": YourNetConfig,
}
```

### 步骤4: 修改主程序

更新 `main.py` 以支持新模型：

```python
p.add_argument("--model", type=str, default="vgg16", 
               choices=["vgg16", "vgg11", "vgg13", "vgg19", "alexnet", "yournet"],
               help="选择模型架构")
```

在训练和评估函数中使用配置：
```python
from model_configs import get_model_config

config = get_model_config(args.model)
model = config.create_model()
layer_names = config.get_layer_names()
```

---

## AlexNet示例

已提供完整的AlexNet实现作为示例，参见 `model_alexnet_tap_quant.py`。

### AlexNet的网络结构

```
输入: [B, 3, 32, 32] (CIFAR-10)

特征提取:
  conv1: 3 -> 64,  k=5, s=1, p=2  ->  MaxPool(2,2)  -> [B, 64, 16, 16]
  conv2: 64 -> 192, k=5, s=1, p=2  ->  MaxPool(2,2)  -> [B, 192, 8, 8]
  conv3: 192 -> 384, k=3, s=1, p=1                   -> [B, 384, 8, 8]
  conv4: 384 -> 256, k=3, s=1, p=1                   -> [B, 256, 8, 8]
  conv5: 256 -> 256, k=3, s=1, p=1  ->  MaxPool(2,2)  -> [B, 256, 4, 4]
  
  AdaptiveAvgPool2d(2,2)  -> [B, 256, 2, 2]
  Flatten  -> [B, 1024]

分类器:
  fc1: 1024 -> 1024  (with BN + ReLU)
  fc2: 1024 -> 512   (with BN + ReLU)
  fc3: 512 -> 10
  
输出: [B, 10]
```

### 使用AlexNet训练

```bash
# 1. 训练浮点模型
python main.py float --model alexnet --epochs 20

# 2. QAT训练
python main.py qat --model alexnet --qat-epochs 10

# 3. 导出INT8模型
python main.py export-int8 --model alexnet

# 4. PPO近似探索
python main.py ppo --model alexnet --episodes 500

# 5. 评估INT8模型
python main.py eval-int8 --model alexnet
```

---

## 其他网络示例

### VGG11 结构 (1-1-2-2-2)

```python
# VGG11: 8个卷积层
blocks = {
    "block1": ["conv1_1"],                          # 64
    "block2": ["conv2_1"],                          # 128
    "block3": ["conv3_1", "conv3_2"],               # 256, 256
    "block4": ["conv4_1", "conv4_2"],               # 512, 512
    "block5": ["conv5_1", "conv5_2"],               # 512, 512
}
```

### VGG13 结构 (2-2-2-2-2)

```python
# VGG13: 10个卷积层
blocks = {
    "block1": ["conv1_1", "conv1_2"],               # 64, 64
    "block2": ["conv2_1", "conv2_2"],               # 128, 128
    "block3": ["conv3_1", "conv3_2"],               # 256, 256
    "block4": ["conv4_1", "conv4_2"],               # 512, 512
    "block5": ["conv5_1", "conv5_2"],               # 512, 512
}
```

### VGG19 结构 (2-2-4-4-4)

```python
# VGG19: 16个卷积层
blocks = {
    "block1": ["conv1_1", "conv1_2"],                            # 64, 64
    "block2": ["conv2_1", "conv2_2"],                            # 128, 128
    "block3": ["conv3_1", "conv3_2", "conv3_3", "conv3_4"],      # 256 x4
    "block4": ["conv4_1", "conv4_2", "conv4_3", "conv4_4"],      # 512 x4
    "block5": ["conv5_1", "conv5_2", "conv5_3", "conv5_4"],      # 512 x4
}
```

### 创建VGG变体的模板

```python
class VGG_N_TapQuant(nn.Module):
    def __init__(self, num_classes: int = 10):
        super().__init__()
        self.quant = QuantStub()
        self.dequant = DeQuantStub()
        
        # 根据VGG变体定义层
        # VGG11: [1, 1, 2, 2, 2]
        # VGG13: [2, 2, 2, 2, 2]
        # VGG16: [2, 2, 3, 3, 3]
        # VGG19: [2, 2, 4, 4, 4]
        
        cfg = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']
        # 根据cfg构建网络...
```

---

## 常见问题

### Q1: 如何确定层的名称？

**A**: 层名称应该：
- 清晰描述层的位置（如 `conv3_2` 表示第3个block的第2个卷积）
- 与tap点命名保持一致
- 在整个项目中保持统一

### Q2: 为什么要区分融合前后？

**A**: 
- **融合前**（训练阶段）：可以单独访问conv、bn、relu的输出，便于分析
- **融合后**（推理阶段）：conv+bn+relu融合成一个操作，提高推理速度

### Q3: 如何处理不带BN的网络？

**A**: 可以省略BN相关的记录点：
```python
def conv_seq_no_bn(in_ch, out_ch, k=3, s=1, p=1):
    return nn.Sequential(OrderedDict([
        ("conv", nn.Conv2d(in_ch, out_ch, k, s, p)),
        ("relu", nn.ReLU(inplace=True)),
    ]))

def fuse_model(self):
    # 只融合conv+relu
    fuse_modules(m, ["conv", "relu"], inplace=True)
```

### Q4: 如何处理残差连接？

**A**: 残差连接需要特殊处理：
```python
def forward(self, x, recorder=None):
    identity = x
    
    # 主路径
    out = self._forward_convseq(x, self.conv1, "conv1", recorder)
    out = self._forward_convseq(out, self.conv2, "conv2", recorder)
    
    # 残差连接
    out = out + identity
    
    if recorder is not None:
        recorder.record("residual_output", out)
    
    return out
```

### Q5: 全连接层需要记录吗？

**A**: 根据需求决定：
- 如果只关注卷积层的近似，可以不记录FC层
- 如果想探索FC层的近似，需要添加类似的记录机制
- AlexNet示例中展示了如何记录FC层

### Q6: 如何验证新模型是否正确？

**A**: 运行以下测试：
```python
# 1. 测试模型创建
from model_configs import get_model_config
config = get_model_config("alexnet")
model = config.create_model()

# 2. 测试前向传播
x = torch.randn(2, 3, 32, 32)
y = model(x)
assert y.shape == (2, 10)

# 3. 测试融合
model.eval()
model.fuse_model()

# 4. 测试量化
from torch.ao.quantization import prepare_qat, convert
model.train()
qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')
model.qconfig = qconfig
prepare_qat(model, inplace=True)
# 训练...
model.eval()
convert(model, inplace=True)
```

### Q7: 如何调试记录器？

**A**: 使用recorder的debug模式：
```python
from recorder import ActivationRecorder

rec = ActivationRecorder()
model = YourNetTapQuant()
x = torch.randn(1, 3, 32, 32)

with torch.no_grad():
    y = model(x, recorder=rec)

# 检查所有记录的激活
print("记录的tap点：")
for key in rec.acts.keys():
    print(f"  {key}: {rec.acts[key].shape}")

# 验证tap点名称
expected_tap_points = config.get_tap_points()
for layer_name, tap_name in expected_tap_points.items():
    assert tap_name in rec.acts, f"缺少tap点: {tap_name}"
```

---

## 总结

添加新网络的关键步骤：

1. ✅ 创建模型文件，实现带记录器的forward方法
2. ✅ 实现fuse_model()方法
3. ✅ 遵循统一的tap点命名规范
4. ✅ 在model_configs.py中注册新模型
5. ✅ 更新main.py支持新模型选择
6. ✅ 测试模型创建、前向传播、融合、量化

参考文件：
- **AlexNet示例**: `model_alexnet_tap_quant.py`
- **VGG16参考**: `model_vgg16_tap_quant.py`
- **配置系统**: `model_configs.py`
- **记录器**: `recorder.py`

有问题可以参考这些文件的实现！
